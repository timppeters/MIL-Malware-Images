from __future__ import print_function

import pandas as pd
from tqdm import tqdm
import comet_ml

import argparse
import torch
import torch.utils.data as data_utils
import torch.optim as optim
import torch.nn as nn
from efficientnet_pytorch import EfficientNet
from torchvision import transforms
import torchmetrics
from torchinfo import summary

from dataloader import Malware
from model import CNN, EfficientNetModel

# Training settings
parser = argparse.ArgumentParser(description='PyTorch Malware Classification (resizing) Example')
parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')
parser.add_argument('--model', type=str, default='CNN', help='Choose b/w CNN, efficientnet')
parser.add_argument('--bags_dir_train', type=str, required=True, help='Directory of training samples')
parser.add_argument('--labels_file_train', type=str, required=True, help='Path to traninng labels csv')
parser.add_argument('--bags_dir_test', type=str, required=True, help='Directory of test samples')
parser.add_argument('--labels_file_test', type=str, required=True, help='Path to test labels csv')
parser.add_argument('--class_names_file', type=str, required=True, help='Path to class names csv')
parser.add_argument('--small_images_dir', type=str, required=False, help='Directory of small images of samples')
parser.add_argument('--adversarial', action='store_true', default=False, help='Adversarial test set')
parser.add_argument('--adversarial_type', type=str, default="zeros", help='Type of adversarial padding')
args = parser.parse_args()

# CometML logging setup
comet_ml.init(project_name="article", offline_directory="comet")
experiment = comet_ml.OfflineExperiment()

hyper_params = {"batch_size": 48, "epochs": 20, "seed": 42, "adversarial": args.adversarial, "dataset": "Microsoft_BIG_2015"}
experiment.log_parameters(hyper_params)
experiment.set_name(f"Base_{args.model}_batch{hyper_params['batch_size']}_{hyper_params['dataset']}{f'_{args.adversarial_type.upper()}adversarial' if hyper_params['adversarial'] else ''}_Bilinear")
experiment.log_code("dataloader.py")
experiment.log_code("model.py")

torch.manual_seed(hyper_params['seed'])
args.cuda = not args.no_cuda and torch.cuda.is_available()
if args.cuda:
    torch.cuda.manual_seed(hyper_params['seed'])
    print('\nGPU is ON!')
if not torch.cuda.is_available():
    print("CUDA is NOT AVAILABLE")

class_names = pd.read_csv(args.class_names_file)["Family"].tolist()
print(f"Classes: {class_names}")
num_classes = len(class_names)
print(f"num_classes: {num_classes}")

# Pre-load efficientNet for Alpha Cluster (jobs have no internet access but login nodes do)
#ef = EfficientNet.from_pretrained('efficientnet-b1')

print('Init Model')
if args.model=='CNN':
    model = CNN(num_classes)
    channels = 1
    tfms = transforms.Compose([transforms.ToTensor()])
elif args.model=='efficientnet':
    model = EfficientNetModel(num_classes)
    channels = 3
    tfms = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])

if args.cuda:
    model.cuda()

# Print model summary
summary(model, input_size=(48, 1, 224, 224))

print('Load Train and Test Set')
loader_kwargs = {'num_workers': 4, 'pin_memory': True} if args.cuda else {}

train_loader = data_utils.DataLoader(Malware(mal_dir=args.bags_dir_train,
                                               labels_file=args.labels_file_train,
                                               transform=tfms,
                                               channels=channels,
                                               small_images_dir=args.small_images_dir
                                               ),
                                     batch_size=hyper_params['batch_size'],
                                     shuffle=True,
                                     **loader_kwargs)

test_loader = data_utils.DataLoader(Malware(mal_dir=args.bags_dir_test,
                                               labels_file=args.labels_file_test,
                                               transform=tfms,
                                               channels=channels,
                                               test=True,
                                               small_images_dir=args.small_images_dir
                                               ),
                                     batch_size=hyper_params['batch_size'],
                                     shuffle=False,
                                     **loader_kwargs)
small_images_dir_adv = "data_sets/BIG2015/train_images_small_adversarial" if args.adversarial_type == "zeros" else "data_sets/BIG2015/train_images_small_adv_noise"
if hyper_params['adversarial']:
    test_adversarial_loader = data_utils.DataLoader(Malware(mal_dir=args.bags_dir_test,
                                                labels_file=args.labels_file_test,
                                                transform=tfms,
                                                channels=channels,
                                                test=True,
                                                adversarial=True,
                                                adversarial_type=args.adversarial_type,
                                                small_images_dir=small_images_dir_adv,
                                                ),
                                        batch_size=hyper_params['batch_size'],
                                        shuffle=False,
                                        **loader_kwargs)


optimizer = optim.Adam(model.parameters())
criterion = nn.CrossEntropyLoss()

# Initialize metrics
accuracy_metric = torchmetrics.Accuracy(task="multiclass", num_classes=num_classes).cuda()
f1_metric = torchmetrics.F1Score(task="multiclass", num_classes=num_classes, average="macro").cuda()
AUC_metric = torchmetrics.AUROC(task="multiclass", num_classes=num_classes).cuda()
ROC_metric = torchmetrics.ROC(task="multiclass", num_classes=num_classes).cuda()
confusion_matrix = experiment.create_confusion_matrix(row_label="Actual family", column_label="Predicted family", labels=class_names)

def train(epoch):
    model.train()

    train_loss = 0.
    train_total = 0

    loop = tqdm(train_loader, ascii=True, desc=f"Epoch [{epoch}/{hyper_params['epochs']}]") # For progress bar

    for batch_idx, (data, labels) in enumerate(train_loader):
        if args.cuda:
            data, labels = data.cuda(), labels.cuda()

        # Reset gradients
        optimizer.zero_grad()

        # Forward pass
        Y_prob = model(data)
        prediction = torch.nn.functional.softmax(Y_prob, dim=1)

        # Calculate loss
        loss = criterion(Y_prob, labels)     
        
        # Backward pass
        loss.backward()

        # Step
        optimizer.step()

        # Calculate metrics
        train_loss += loss.item()*labels.size(0)
        train_total += labels.size(0)
        acc = accuracy_metric(prediction, labels).item()
        f1 = f1_metric(prediction, labels).item()
        AUC_metric(prediction, labels)
        ROC_metric(prediction, labels)

        # Print Loss, Train Accuracy, Train F1 after every batch
        running_loss = train_loss / train_total
        loop.set_postfix(loss=running_loss, acc=acc, f1=f1)
        loop.update()

    # Calculate loss, metrics for epoch
    train_loss /= len(train_loader.dataset)
    acc = accuracy_metric.compute().item()
    f1 = f1_metric.compute().item()
    auc = AUC_metric.compute().item()
    fpr, tpr, _ = ROC_metric.compute()
    loop.set_postfix(loss=train_loss, acc=acc, f1=f1)
    loop.close()

    # Log metrics
    experiment.log_metrics({"loss": train_loss, "accuracy": acc, "f1": f1, "AUROC": auc}, epoch=epoch)
    for i, class_name in enumerate(class_names):
        experiment.log_curve(f"roc-curve-class-{class_name}", fpr[i].tolist(), tpr[i].tolist(), step=epoch)

    # Reset metrics
    accuracy_metric.reset()
    f1_metric.reset()
    AUC_metric.reset()
    ROC_metric.reset()

def test(epoch, data_loader=test_loader, name="Test"):
    model.eval()

    test_loss = 0.
    test_total = 0
    test_labels = []
    test_predictions = []

    with torch.no_grad():
        loop = tqdm(data_loader, ascii=True, desc=name)
        for batch_idx, (data, labels) in enumerate(data_loader):
            if args.cuda:
                data, labels = data.cuda(), labels.cuda()

            # Get prediction
            Y_prob = model(data)
            prediction = torch.nn.functional.softmax(Y_prob, dim=1)

            # Calculate loss
            loss = criterion(Y_prob, labels)

            # Calculate metrics
            test_loss += loss.item()*labels.size(0)
            test_total += labels.size(0)
            acc = accuracy_metric(prediction, labels).item()
            f1 = f1_metric(prediction, labels).item()
            AUC_metric(prediction, labels)
            ROC_metric(prediction, labels)
            test_labels.extend(labels.cpu())
            test_predictions.extend(prediction.cpu().numpy())

            # Print Loss, Train Accuracy, Train F1 after every batch
            running_loss = test_loss / test_total
            loop.set_postfix(loss=running_loss, acc=acc, f1=f1)
            loop.update()
            
        # Calculate loss, metrics for epoch
        test_loss /= len(data_loader.dataset)
        acc = accuracy_metric.compute().item()
        f1 = f1_metric.compute().item()
        auc = AUC_metric.compute().item()
        fpr, tpr, _ = ROC_metric.compute()
        loop.set_postfix(loss=test_loss, acc=acc, f1=f1)
        loop.close()

        # Log metrics
        experiment.log_metrics({"loss": test_loss, "accuracy": acc, "f1": f1, "AUROC": auc}, epoch=epoch)
        for i, class_name in enumerate(class_names):
            experiment.log_curve(f"roc-curve-class-{class_name}", fpr[i].tolist(), tpr[i].tolist(), step=epoch)

        # Generate and log confusion matrix
        confusion_matrix.compute_matrix(test_labels, test_predictions, images=data_loader.dataset.images_sorted, index_to_example_function=lambda index: CM_index_to_example(index, data_loader))
        experiment.log_confusion_matrix(matrix=confusion_matrix, file_name=f"{name}-confusion-matrix-epoch-{epoch}.json")

        # Save model on last epoch
        if (epoch == hyper_params['epochs']):
            torch.save(model.state_dict(), f"models/base/{experiment.get_name()}_epoch{epoch}.model")
            experiment.log_model(f"{experiment.get_name()}_epoch{epoch}", f"models/base/{experiment.get_name()}_epoch{epoch}.model")

        # Reset metrics
        accuracy_metric.reset()
        f1_metric.reset()
        AUC_metric.reset()
        ROC_metric.reset()
        confusion_matrix.clear()

# Helper function to upload sample images with the confusion matrix
def CM_index_to_example(index, data_loader):
    image = data_loader.dataset.images_sorted[index]
    if (channels == 3):
        image = image.permute((1, 2, 0)) # Change (3, 224, 224) to (224, 224, 3)
    sample_id = data_loader.dataset.get_sample_id_by_index(index)
    image_name= f"{sample_id}.bmp"
    result = experiment.log_image(image, name=image_name, image_format="bmp")
    return {"index": index, "sample": image_name, "assetId": result["imageId"]}


if __name__ == "__main__":
    print('Start Training')
    for epoch in range(1, hyper_params['epochs'] + 1):
        with experiment.train():
            train(epoch)
        with experiment.validate():
            test(epoch)
        if hyper_params["adversarial"]:
            with experiment.context_manager("validate_adversarial"):
                test(epoch, test_adversarial_loader, "Test Adversarial")
        print()
    
