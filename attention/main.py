from __future__ import print_function

import pandas as pd
import numpy as np
from tqdm import tqdm
import comet_ml

import argparse
import torch
import torch.utils.data as data_utils
import torch.optim as optim
import torch.nn as nn
from efficientnet_pytorch import EfficientNet
from torchvision import transforms
import torchmetrics
from torchinfo import summary

from dataloader import MalwareBags
from model import Attention, GatedAttention, EfficientNetMIL

# Training settings
parser = argparse.ArgumentParser(description='PyTorch Malware Classification MIL Example')
parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')
parser.add_argument('--model', type=str, default='attention', help='Choose b/w attention, gated attention, and efficientnet')
parser.add_argument('--bags_dir_train', type=str, required=True, help='Directory of training samples')
parser.add_argument('--labels_file_train', type=str, required=True, help='Path to traninng labels csv')
parser.add_argument('--bags_dir_test', type=str, required=True, help='Directory of test samples')
parser.add_argument('--labels_file_test', type=str, required=True, help='Path to test labels csv')
parser.add_argument('--class_names_file', type=str, required=True, help='Path to class names csv')
parser.add_argument('--small_images_dir', type=str, required=False, help='Directory of small images of samples')
parser.add_argument('--adversarial', action='store_true', default=False, help='Adversarial test set')
parser.add_argument('--adversarial_type', type=str, default="zeros", help='Type of adversarial padding')
args = parser.parse_args()

# CometML logging setup
comet_ml.init(project_name="article", offline_directory="./comet")
experiment = comet_ml.OfflineExperiment()

hyper_params = {"batch_size": 48, "epochs": 20, "learning_rate": 0.0005, "seed": 42, "adversarial": args.adversarial, "dataset": "Microsoft_BIG_2015"}
experiment.log_parameters(hyper_params)
experiment.set_name(f"MIL_{args.model}_batch{hyper_params['batch_size']}_{hyper_params['dataset']}{f'_{args.adversarial_type.upper()}adversarial' if hyper_params['adversarial'] else ''}_Bilinear")
experiment.log_code("dataloader.py")
experiment.log_code("model.py")

torch.manual_seed(hyper_params['seed'])
args.cuda = not args.no_cuda and torch.cuda.is_available()
if args.cuda:
    torch.cuda.manual_seed(hyper_params['seed'])
    print('\nGPU is ON!')
if not torch.cuda.is_available():
    print("CUDA is NOT AVAILABLE")

class_names = pd.read_csv(args.class_names_file)["Family"].tolist()
print(f"Classes: {class_names}")
num_classes = len(class_names)
print(f"num_classes: {num_classes}")

# Pre-load efficientNet for Alpha Cluster (jobs have no internet access but login nodes do)
#ef = EfficientNet.from_pretrained('efficientnet-b1')

print('Init Model')
if args.model=='attention':
    model = Attention(num_classes)
    channels = 1
    tfms = transforms.Compose([transforms.ToTensor()])
elif args.model=='gated':
    model = GatedAttention(num_classes)
    channels = 1
    tfms = transforms.Compose([transforms.ToTensor()])
elif args.model=='efficientnet':
    model = EfficientNetMIL(num_classes)
    channels = 3
    tfms = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])

if args.cuda:
    model.cuda()

# Print model summary
summary(model, input_size=(1, 60, 1, 224, 224))
    
print('Load Train and Test Set')
loader_kwargs = {'num_workers': 8, 'pin_memory': True} if args.cuda else {}

train_loader = data_utils.DataLoader(MalwareBags(bags_dir=args.bags_dir_train,
                                               labels_file=args.labels_file_train,
                                               transform=tfms,
                                               channels=channels,
                                               small_images_dir=args.small_images_dir),
                                     batch_size=1,
                                     shuffle=True,
                                     **loader_kwargs)

test_loader = data_utils.DataLoader(MalwareBags(bags_dir=args.bags_dir_test,
                                               labels_file=args.labels_file_test,
                                               transform=tfms,
                                               channels=channels,
                                               test=True,
                                               small_images_dir=args.small_images_dir),
                                     batch_size=1,
                                     shuffle=False,
                                     **loader_kwargs)

if hyper_params['adversarial']:
    test_adversarial_loader = data_utils.DataLoader(MalwareBags(bags_dir=args.bags_dir_test,
                                                labels_file=args.labels_file_test,
                                                transform=tfms,
                                                channels=channels,
                                                test=True,
                                                adversarial=True,
                                                adversarial_type=args.adversarial_type,
                                                small_images_dir=None,
                                                lazy=True),
                                        batch_size=1,
                                        shuffle=False,
                                        **loader_kwargs)

optimizer = optim.Adam(model.parameters(), lr=hyper_params['learning_rate'])
criterion = nn.CrossEntropyLoss()

# Initialize metrics
accuracy_metric = torchmetrics.Accuracy(task="multiclass", num_classes=num_classes).cuda()
f1_metric = torchmetrics.F1Score(task="multiclass", num_classes=num_classes, average="macro")
AUC_metric = torchmetrics.AUROC(task="multiclass", num_classes=num_classes).cuda()
ROC_metric = torchmetrics.ROC(task="multiclass", num_classes=num_classes).cuda()
confusion_matrix = experiment.create_confusion_matrix(row_label="Actual family", column_label="Predicted family", labels=class_names)

def train(epoch):
    model.train()

    train_loss = 0.
    train_total = 0
    accum_batch_labels = []
    accum_batch_predictions = []

    loop = tqdm(train_loader, ascii=True, desc=f"Epoch [{epoch}/{hyper_params['epochs']}]") # For progress bar

    for batch_idx, (data, bag_label) in enumerate(train_loader):

        if args.cuda:
            data, bag_label = data.cuda(), bag_label.cuda()

        # Forward pass
        Y_prob, _ = model(data)
        prediction = torch.nn.functional.softmax(Y_prob, dim=1)

        # Calculate loss and error
        loss = criterion(Y_prob, bag_label)      
        
        # Backward pass
        loss.backward()
        train_loss += loss.item()

        # Accumulate predictions to calculate batch metrics
        accum_batch_labels.append(bag_label.cpu())
        accum_batch_predictions.append(prediction.detach().cpu())

        # After every 48 bags (or last bag), update gradients 
        if (batch_idx+1) % 48 == 0 or batch_idx+1 == len(train_loader):  
            # Step
            optimizer.step()

            # Reset gradients
            optimizer.zero_grad()

            # Calculate metrics
            accum_batch_labels = torch.cat(accum_batch_labels)
            accum_batch_predictions = torch.cat(accum_batch_predictions)
            train_total += accum_batch_labels.size(0)
            acc = accuracy_metric(accum_batch_predictions, accum_batch_labels).item()
            f1 = f1_metric(accum_batch_predictions, accum_batch_labels).item()
            AUC_metric(accum_batch_predictions, accum_batch_labels)
            ROC_metric(accum_batch_predictions, accum_batch_labels)

            # Print Running Loss, batch Accuracy, batch F1 after every accum batch
            running_loss = train_loss / train_total
            loop.set_postfix(loss=running_loss, acc=acc, f1=f1)

            accum_batch_labels = []
            accum_batch_predictions = []
        
        loop.update()

    # Calculate loss, metrics for epoch
    train_loss /= len(train_loader.dataset)
    acc = accuracy_metric.compute().item()
    f1 = f1_metric.compute().item()
    auc = AUC_metric.compute().item()
    fpr, tpr, _ = ROC_metric.compute()
    loop.set_postfix(loss=train_loss, acc=acc, f1=f1)
    loop.close()

    # Log metrics
    experiment.log_metrics({"loss": train_loss, "accuracy": acc, "f1": f1, "AUROC": auc}, epoch=epoch)
    for i, class_name in enumerate(class_names):
        experiment.log_curve(f"roc-curve-class-{class_name}", fpr[i].tolist(), tpr[i].tolist(), step=epoch)

    # Reset metrics
    accuracy_metric.reset()
    f1_metric.reset()
    AUC_metric.reset()
    ROC_metric.reset()

    torch.cuda.empty_cache()

def test(epoch, data_loader=test_loader, name="Test"):
    model.eval()

    test_loss = 0.
    test_total = 0
    test_labels = []
    test_predictions = []
    attention_weights_all = []

    with torch.no_grad():
        loop = tqdm(data_loader, ascii=True, desc=name)
        for batch_idx, (data, bag_label) in enumerate(data_loader):

            if args.cuda:
                data, bag_label = data.cuda(), bag_label.cuda()

            # Get prediction
            Y_prob, attention_weights = model(data)
            prediction = torch.nn.functional.softmax(Y_prob, dim=1)

            attention_weights_all.append(attention_weights.cpu().numpy())

            # Calculate loss and error
            loss = criterion(Y_prob, bag_label)

            # Calculate metrics
            test_loss += loss.item()
            test_total += 1
            acc = accuracy_metric(prediction, bag_label).item()
            f1 = f1_metric(prediction.cpu(), bag_label.cpu()).item()
            AUC_metric(prediction, bag_label)
            ROC_metric(prediction, bag_label)
            test_labels.extend(bag_label.cpu())
            test_predictions.extend(prediction.cpu().numpy())

            # Print Running Loss, batch accuracy, batch F1 after every sample
            running_loss = test_loss / test_total
            loop.set_postfix(loss=running_loss, acc=acc, f1=f1)
            loop.update()

        # Calculate loss, metrics for epoch
        test_loss /= len(data_loader.dataset)
        acc = accuracy_metric.compute().item()
        f1 = f1_metric.compute().item()
        auc = AUC_metric.compute().item()
        fpr, tpr, _ = ROC_metric.compute()
        loop.set_postfix(loss=test_loss, acc=acc, f1=f1)
        loop.close()

        # Log metrics
        experiment.log_metrics({"loss": test_loss, "accuracy": acc, "f1": f1, "AUROC": auc}, epoch=epoch)
        for i, class_name in enumerate(class_names):
            experiment.log_curve(f"roc-curve-class-{class_name}", fpr[i].tolist(), tpr[i].tolist(), step=epoch)

        # Generate and log confusion matrix
        # data_loader.dataset.create_images_sorted()
        confusion_matrix.compute_matrix(test_labels, test_predictions, images=data_loader.dataset.images_sorted, index_to_example_function=lambda index: CM_index_to_example(index, data_loader))
        experiment.log_confusion_matrix(matrix=confusion_matrix, file_name=f"{name}-confusion-matrix-epoch-{epoch}.json")

        # Save model on last epoch
        if (epoch == hyper_params['epochs']):
            torch.save(model.state_dict(), f"models/MIL/{experiment.get_name()}_epoch{epoch}.model")
            experiment.log_model(f"{experiment.get_name()}_epoch{epoch}", f"models/MIL/{experiment.get_name()}_epoch{epoch}.model")
        
            if (name == "Test Adversarial"):
                # Save attention weights
                np.savez(f"weights/attention_{experiment.get_name()}.npz", bags=np.asanyarray(data_loader.dataset.og_images, dtype=object), attentionweights=attention_weights_all)

        # Reset metrics
        accuracy_metric.reset()
        f1_metric.reset()
        AUC_metric.reset()
        ROC_metric.reset()
        confusion_matrix.clear()

        torch.cuda.empty_cache()

# Helper function to upload sample images with the confusion matrix
def CM_index_to_example(index, data_loader):
    image = data_loader.dataset.images_sorted[index]
    sample_id = data_loader.dataset.get_sample_id_by_index(index)
    image_name= f"{sample_id}.bmp"
    result = experiment.log_image(image, name=image_name, image_format="bmp")
    return {"index": index, "sample": image_name, "assetId": result["imageId"]}

if __name__ == "__main__":
    print('Start Training')
    for epoch in range(1, hyper_params['epochs'] + 1):
        with experiment.train():
            train(epoch)
        with experiment.validate():
            test(epoch)
        if hyper_params["adversarial"]:
            with experiment.context_manager("validate_adversarial"):
                test(epoch, test_adversarial_loader, "Test Adversarial")
        print()
    
