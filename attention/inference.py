from __future__ import print_function

import pandas as pd
import numpy as np
from tqdm import tqdm
import comet_ml
import time

import argparse
import torch
import torch.utils.data as data_utils
from efficientnet_pytorch import EfficientNet
from torchvision import transforms
from torchinfo import summary

from inference_dataloader import MalwareBags
from model import Attention, EfficientNetMIL

# Training settings
parser = argparse.ArgumentParser(description='PyTorch Malware Classification MIL Example')
parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')
parser.add_argument('--model', type=str, default='attention', help='Choose b/w attention, gated attention, and efficientnet')
parser.add_argument('--bags_dir_train', type=str, required=True, help='Directory of training samples')
parser.add_argument('--labels_file_train', type=str, required=True, help='Path to traninng labels csv')
parser.add_argument('--bags_dir_test', type=str, required=True, help='Directory of test samples')
parser.add_argument('--labels_file_test', type=str, required=True, help='Path to test labels csv')
parser.add_argument('--class_names_file', type=str, required=True, help='Path to class names csv')
parser.add_argument('--small_images_dir', type=str, required=False, help='Directory of small images of samples')
parser.add_argument('--adversarial', action='store_true', default=False, help='Adversarial test set')
parser.add_argument('--adversarial_type', type=str, default="zeros", help='Type of adversarial padding')
parser.add_argument('--model_path', type=str, required=True, help='Path of the saved model')
args = parser.parse_args()

# CometML logging setup
comet_ml.init(project_name="article", offline_directory="comet")
experiment = comet_ml.OfflineExperiment()

hyper_params = {"batch_size": 48, "epochs": 20, "learning_rate": 0.0005, "seed": 42, "adversarial": args.adversarial, "dataset": "Microsoft_BIG_2015"}
#experiment.log_parameters(hyper_params)
experiment.set_name(f"INFERENCE_MIL_{args.model}_{f'_{args.adversarial_type.upper()}adversarial' if hyper_params['adversarial'] else ''}")
experiment.log_code("inference_dataloader.py")
experiment.log_code("model.py")

torch.manual_seed(hyper_params['seed'])
args.cuda = not args.no_cuda and torch.cuda.is_available()
if args.cuda:
    torch.cuda.manual_seed(hyper_params['seed'])
    print('\nGPU is ON!')
if not torch.cuda.is_available():
    print("CUDA is NOT AVAILABLE")

class_names = pd.read_csv(args.class_names_file)["Family"].tolist()
print(f"Classes: {class_names}")
num_classes = len(class_names)
print(f"num_classes: {num_classes}")

# Pre-load efficientNet for Alpha Cluster (jobs have no internet access but login nodes do)
#ef = EfficientNet.from_pretrained('efficientnet-b1')

print('Init Model')
if args.model=='attention':
    model = Attention(num_classes)
    channels = 1
    tfms = transforms.Compose([transforms.ToTensor()])
elif args.model=='gated':
    model = Attention(num_classes)
    channels = 1
    tfms = transforms.Compose([transforms.ToTensor()])
elif args.model=='efficientnet':
    model = EfficientNetMIL(num_classes)
    channels = 3
    tfms = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])

if args.cuda:
    model.cuda()

# Print model summary
summary(model, input_size=(1, 60, 1, 224, 224))
    
print('Load Train and Test Set')
loader_kwargs = {'num_workers': 8, 'pin_memory': True} if args.cuda else {}

if hyper_params['adversarial']:
    test_loader = data_utils.DataLoader(MalwareBags(bags_dir=args.bags_dir_test,
                                                labels_file=args.labels_file_test,
                                                transform=tfms,
                                                channels=channels,
                                                adversarial=True,
                                                adversarial_type=args.adversarial_type,
                                                ),
                                        batch_size=1,
                                        shuffle=False,
                                        **loader_kwargs)
else:
    test_loader = data_utils.DataLoader(MalwareBags(bags_dir=args.bags_dir_test,
                                               labels_file=args.labels_file_test,
                                               transform=tfms,
                                               channels=channels,),
                                     batch_size=1,
                                     shuffle=False,
                                     **loader_kwargs)


model.load_state_dict(torch.load(args.model_path))

def test(data_loader=test_loader, name="Test"):
    model.eval()

    test_IDs = []
    test_predictions = []
    timings = np.zeros((1000,1))

    # INIT LOGGERS
    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)

    #GPU warm-up
    dummy_input = torch.randn(1, 60, 1, 224, 224, dtype=torch.float).cuda()
    for _ in range(10):
        _ = model(dummy_input)

    # Test resize 100 times
    resize_time = 0
    for _ in range(100):
        bin_data = np.random.randint(0, 256, 12*224*224, dtype=np.uint8)
        start_time = time.perf_counter()
        #bin_data.resize(10000*10000)
        pad_data = (np.random.rand(10000*10000 - len(bin_data))*255).astype(np.uint8) # Uniform random noise 0-255
        bin_data = np.concatenate((bin_data, pad_data))
        end_time = time.perf_counter()
        resize_time += (end_time - start_time) * 1000  # time in ms
    print(f"Resize (inflate) time: {resize_time/100}")

    # test make_bag 100 times
    bag_time = 0
    bin_data = np.random.randint(0, 256, 12*224*224, dtype=np.uint8)
    # bin_data.resize(10000*10000)
    pad_data = (np.random.rand(10000*10000 - len(bin_data))*255).astype(np.uint8) # Uniform random noise 0-255
    bin_data = np.concatenate((bin_data, pad_data))
    for _ in range(100):
        start_time = time.perf_counter()
        _ = data_loader.dataset._make_bag(bin_data)
        end_time = time.perf_counter()
        bag_time += (end_time - start_time) * 1000  # time in ms
    print(f"Bag time: {bag_time/100}")

    with torch.no_grad():
        loop = tqdm(data_loader, ascii=True, desc=name)
        for batch_idx, (data, bag_id) in enumerate(data_loader):

            if args.cuda:
                data = data.cuda()

            starter.record()

            # Get prediction
            Y_prob, _ = model(data)

            ender.record()
            # WAIT FOR GPU SYNC
            torch.cuda.synchronize()
            curr_time = starter.elapsed_time(ender)
            timings[batch_idx] = curr_time

            prediction = torch.nn.functional.softmax(Y_prob, dim=1)
            class_prediction = torch.argmax(prediction, dim=1)

            # Save predictions
            test_predictions.extend(class_prediction.cpu().numpy())
            test_IDs.extend(bag_id)

            # Print after every sample
            loop.update()

        loop.close()

        torch.cuda.empty_cache()

    print("Average time: ", np.mean(timings))
    out = pd.DataFrame({'ID': test_IDs, 'prediction': test_predictions})
    out.to_csv(f"inference/{experiment.get_name()}.csv")

if __name__ == "__main__":
    print('Start Inferencing')
    with experiment.validate():
        test()
    
